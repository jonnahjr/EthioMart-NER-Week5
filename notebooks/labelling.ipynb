{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Message 2: Saachi Electric Kettle \n",
      " የውሀ ማፍያ ቦይለር \n",
      " 1.8ሊትር የሆነ \n",
      " 2200W \n",
      " Automatic switch off \n",
      " ውስጡ Stainless steel የሆነ \n",
      "  ለአጠቃቀም በጣም ቀላል \n",
      "\n",
      "                 በ \n",
      "            2700 \n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "                      \n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "አዲስ አበባ ዉስጥ ከ100ብር እስከ 200ብር ብቻ በማስከፈል ያሉበት ድረስ በፈጣን ሞተረኞቻችን እንልክልዏታለን። \n",
      "\n",
      "አድራሻ=ቁጥር 1 = ጉርድሾላ ከሴንቸሪ ሞል ትንሽ ዝቅ እንዳሉ ሆሊሲቲ ሴንተር ላይ እንደገቡ ፊትለፊት ከሊፍቱ በግራ በኩል  ሚዛን ላይ M06\n",
      "           ቁጥር 2 = ጀሞ መስታወትፋብሪካ ፊትለፊት ራሐ ሞል ግራዉንድ ፍሎር ከደረጃዉ ጎን። \n",
      "\n",
      "          በሞደርን እቃወዏች ሂወትዎን\n",
      "                   ሞደርናይዝ ያድርጉ\n",
      "\n",
      "Start labeling each token:\n",
      "Token: Saachi\n",
      "Token: Electric\n",
      "Token: Kettle\n",
      "Token: የውሀ\n",
      "Token: ማፍያ\n",
      "Token: ቦይለር\n",
      "Token: 1.8ሊትር\n",
      "Token: የሆነ\n",
      "Token: 2200W\n",
      "Token: Automatic\n",
      "Token: switch\n",
      "Token: off\n",
      "Token: ውስጡ\n",
      "Token: Stainless\n",
      "Token: steel\n",
      "Token: የሆነ\n",
      "Token: ለአጠቃቀም\n",
      "Token: በጣም\n",
      "Token: ቀላል\n",
      "Token: በ\n",
      "Token: 2700\n",
      "Token: አዲስ\n",
      "Token: አበባ\n",
      "Token: ዉስጥ\n",
      "Token: ከ100ብር\n",
      "Token: እስከ\n",
      "Token: 200ብር\n",
      "Token: ብቻ\n",
      "Token: በማስከፈል\n",
      "Token: ያሉበት\n",
      "Token: ድረስ\n",
      "Token: በፈጣን\n",
      "Token: ሞተረኞቻችን\n",
      "Token: እንልክልዏታለን።\n",
      "Token: አድራሻ=ቁጥር\n",
      "Token: 1\n",
      "Token: =\n",
      "Token: ጉርድሾላ\n",
      "Token: ከሴንቸሪ\n",
      "Token: ሞል\n",
      "Token: ትንሽ\n",
      "Token: ዝቅ\n",
      "Token: እንዳሉ\n",
      "Token: ሆሊሲቲ\n",
      "Token: ሴንተር\n",
      "Token: ላይ\n",
      "Token: እንደገቡ\n",
      "Token: ፊትለፊት\n",
      "Token: ከሊፍቱ\n",
      "Token: በግራ\n",
      "Token: በኩል\n",
      "Token: ሚዛን\n",
      "Token: ላይ\n",
      "Token: M06\n",
      "Token: ቁጥር\n",
      "Token: 2\n",
      "Token: =\n",
      "Token: ጀሞ\n",
      "Token: መስታወትፋብሪካ\n",
      "Token: ፊትለፊት\n",
      "Token: ራሐ\n",
      "Token: ሞል\n",
      "Token: ግራዉንድ\n",
      "Token: ፍሎር\n",
      "Token: ከደረጃዉ\n",
      "Token: ጎን።\n",
      "Token: በሞደርን\n",
      "Token: እቃወዏች\n",
      "Token: ሂወትዎን\n",
      "Token: ሞደርናይዝ\n",
      "Token: ያድርጉ\n",
      "\n",
      "Message 3: Single cup Coffe maker\n",
      " በኤሌክትሪክ የሚሰራ የብና ማፍያ\n",
      " መጠጫ ና መቅጃ የሚሆን ማግ ከነ ክዳኑ \n",
      " ከማይዝግ ብረት የተሰራ\n",
      " ቶሎ የማያቀዘቅዝ እና ለጉዞ የሚሆን ማግ\n",
      " ለአጠቃቀም ቀላል \n",
      "        \n",
      "                በ\n",
      "          2700          \n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "                      \n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "አዲስ አበባ ዉስጥ ከ100ብር እስከ 200ብር ብቻ በማስከፈል ያሉበት ድረስ በፈጣን ሞተረኞቻችን እንልክልዏታለን። \n",
      "\n",
      "አድራሻ=ቁጥር 1 = ጉርድሾላ ከሴንቸሪ ሞል ትንሽ ዝቅ እንዳሉ ሆሊሲቲ ሴንተር ላይ እንደገቡ ፊትለፊት ከሊፍቱ በግራ በኩል  ሚዛን ላይ M06\n",
      "           ቁጥር 2 = ጀሞ መስታወትፋብሪካ ፊትለፊት ራሐ ሞል ግራዉንድ ፍሎር ከደረጃዉ ጎን። \n",
      "\n",
      "          በሞደርን እቃወዏች ሂወትዎን\n",
      "                   ሞደርናይዝ ያድርጉ\n",
      "\n",
      "Start labeling each token:\n",
      "Token: Single\n",
      "Token: cup\n",
      "Token: Coffe\n",
      "Token: maker\n",
      "Token: በኤሌክትሪክ\n",
      "Token: የሚሰራ\n",
      "Token: የብና\n",
      "Token: ማፍያ\n",
      "Token: መጠጫ\n",
      "Token: ና\n",
      "Token: መቅጃ\n",
      "Token: የሚሆን\n",
      "Token: ማግ\n",
      "Token: ከነ\n",
      "Token: ክዳኑ\n",
      "Token: ከማይዝግ\n",
      "Token: ብረት\n",
      "Token: የተሰራ\n",
      "Token: ቶሎ\n",
      "Token: የማያቀዘቅዝ\n",
      "Token: እና\n",
      "Token: ለጉዞ\n",
      "Token: የሚሆን\n",
      "Token: ማግ\n",
      "Token: ለአጠቃቀም\n",
      "Token: ቀላል\n",
      "Token: በ\n",
      "Token: 2700\n",
      "Token: አዲስ\n",
      "Token: አበባ\n",
      "Token: ዉስጥ\n",
      "Token: ከ100ብር\n",
      "Token: እስከ\n",
      "Token: 200ብር\n",
      "Token: ብቻ\n",
      "Token: በማስከፈል\n",
      "Token: ያሉበት\n",
      "Token: ድረስ\n",
      "Token: በፈጣን\n",
      "Token: ሞተረኞቻችን\n",
      "Token: እንልክልዏታለን።\n",
      "Token: አድራሻ=ቁጥር\n",
      "Token: 1\n",
      "Token: =\n",
      "Token: ጉርድሾላ\n",
      "Token: ከሴንቸሪ\n",
      "Token: ሞል\n",
      "Token: ትንሽ\n",
      "Token: ዝቅ\n",
      "Token: እንዳሉ\n",
      "Token: ሆሊሲቲ\n",
      "Token: ሴንተር\n",
      "Token: ላይ\n",
      "Token: እንደገቡ\n",
      "Token: ፊትለፊት\n",
      "Token: ከሊፍቱ\n",
      "Token: በግራ\n",
      "Token: በኩል\n",
      "Token: ሚዛን\n",
      "Token: ላይ\n",
      "Token: M06\n",
      "Token: ቁጥር\n",
      "Token: 2\n",
      "Token: =\n",
      "Token: ጀሞ\n",
      "Token: መስታወትፋብሪካ\n",
      "Token: ፊትለፊት\n",
      "Token: ራሐ\n",
      "Token: ሞል\n",
      "Token: ግራዉንድ\n",
      "Token: ፍሎር\n",
      "Token: ከደረጃዉ\n",
      "Token: ጎን።\n",
      "Token: በሞደርን\n",
      "Token: እቃወዏች\n",
      "Token: ሂወትዎን\n",
      "Token: ሞደርናይዝ\n",
      "Token: ያድርጉ\n",
      "\n",
      "Message 4: toilet seat cover\n",
      " የሽንት ቤት መቀመጫ ከቨር ልብስ\n",
      " እንዳይቀዘቅዝ መከላከያ\n",
      " በተለይ ለትልልቅ ሰዎች፣ለህፃናት ተመራጭ\n",
      "ለማፅዳት በጣም ቀላል\n",
      "በዚፕ የሚዘጋ\n",
      "  ለአጠቃቀም ቀላል \n",
      "\n",
      "       በ\n",
      "   650 \n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "                      \n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "አዲስ አበባ ዉስጥ ከ100ብር እስከ 200ብር ብቻ በማስከፈል ያሉበት ድረስ በፈጣን ሞተረኞቻችን እንልክልዏታለን። \n",
      "\n",
      "አድራሻ=ቁጥር 1 = ጉርድሾላ ከሴንቸሪ ሞል ትንሽ ዝቅ እንዳሉ ሆሊሲቲ ሴንተር ላይ እንደገቡ ፊትለፊት ከሊፍቱ በግራ በኩል  ሚዛን ላይ M06\n",
      "           ቁጥር 2 = ጀሞ መስታወትፋብሪካ ፊትለፊት ራሐ ሞል ግራዉንድ ፍሎር ከደረጃዉ ጎን። \n",
      "\n",
      "          በሞደርን እቃወዏች ሂወትዎን\n",
      "                   ሞደርናይዝ ያድርጉ\n",
      "\n",
      "Start labeling each token:\n",
      "Token: toilet\n",
      "Token: seat\n",
      "Token: cover\n",
      "Token: የሽንት\n",
      "Token: ቤት\n",
      "Token: መቀመጫ\n",
      "Token: ከቨር\n",
      "Token: ልብስ\n",
      "Token: እንዳይቀዘቅዝ\n",
      "Token: መከላከያ\n",
      "Token: በተለይ\n",
      "Token: ለትልልቅ\n",
      "Token: ሰዎች፣ለህፃናት\n",
      "Token: ተመራጭ\n",
      "Token: ለማፅዳት\n",
      "Token: በጣም\n",
      "Token: ቀላል\n",
      "Token: በዚፕ\n",
      "Token: የሚዘጋ\n",
      "Token: ለአጠቃቀም\n",
      "Token: ቀላል\n",
      "Token: በ\n",
      "Token: 650\n",
      "Token: አዲስ\n",
      "Token: አበባ\n",
      "Token: ዉስጥ\n",
      "Token: ከ100ብር\n",
      "Token: እስከ\n",
      "Token: 200ብር\n",
      "Token: ብቻ\n",
      "Token: በማስከፈል\n",
      "Token: ያሉበት\n",
      "Token: ድረስ\n",
      "Token: በፈጣን\n",
      "Token: ሞተረኞቻችን\n",
      "Token: እንልክልዏታለን።\n",
      "Token: አድራሻ=ቁጥር\n",
      "Token: 1\n",
      "Token: =\n",
      "Token: ጉርድሾላ\n",
      "Token: ከሴንቸሪ\n",
      "Token: ሞል\n",
      "Token: ትንሽ\n",
      "Token: ዝቅ\n",
      "Token: እንዳሉ\n",
      "Token: ሆሊሲቲ\n",
      "Token: ሴንተር\n",
      "Token: ላይ\n",
      "Token: እንደገቡ\n",
      "Token: ፊትለፊት\n",
      "Token: ከሊፍቱ\n",
      "Token: በግራ\n",
      "Token: በኩል\n",
      "Token: ሚዛን\n",
      "Token: ላይ\n",
      "Token: M06\n",
      "Token: ቁጥር\n",
      "Token: 2\n",
      "Token: =\n",
      "Token: ጀሞ\n",
      "Token: መስታወትፋብሪካ\n",
      "Token: ፊትለፊት\n",
      "Token: ራሐ\n",
      "Token: ሞል\n",
      "Token: ግራዉንድ\n",
      "Token: ፍሎር\n",
      "Token: ከደረጃዉ\n",
      "Token: ጎን።\n",
      "Token: በሞደርን\n",
      "Token: እቃወዏች\n",
      "Token: ሂወትዎን\n",
      "Token: ሞደርናይዝ\n",
      "Token: ያድርጉ\n",
      "\n",
      "Annotated data saved to ../data/labeled_data.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "def load_dataset(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# Function to tokenize the Amharic text (a simple split based on space)\n",
    "def tokenize_message(message):\n",
    "    # Convert to string to avoid issues with float/NaN values\n",
    "    if isinstance(message, str):\n",
    "        return message.split()\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Manual annotation function\n",
    "def annotate_message(tokens):\n",
    "    labeled_tokens = []\n",
    "    print(\"\\nStart labeling each token:\")\n",
    "    for token in tokens:\n",
    "        print(f\"Token: {token}\")\n",
    "        label = input(\"Enter label (B-Product, I-Product, B-LOC, I-LOC, B-PRICE, I-PRICE, O): \")\n",
    "        labeled_tokens.append((token, label))\n",
    "    return labeled_tokens\n",
    "\n",
    "# Save the labeled data in CoNLL format\n",
    "def save_to_conll(labeled_data, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for message in labeled_data:\n",
    "            for token, label in message:\n",
    "                f.write(f\"{token} {label}\\n\")\n",
    "            f.write(\"\\n\")  # Blank line to separate messages\n",
    "\n",
    "# Main function to annotate dataset\n",
    "def main(file_path, output_file, start_row, num_rows):\n",
    "    df = load_dataset(file_path)\n",
    "\n",
    "    labeled_data = []\n",
    "\n",
    "    # Subset the dataframe based on the start_row and num_rows\n",
    "    df_subset = df.iloc[start_row : start_row + num_rows]\n",
    "\n",
    "    # Assuming the dataset has a 'Message' column\n",
    "    for index, row in df_subset.iterrows():\n",
    "        message = row['Message']\n",
    "\n",
    "        # Tokenize the message (handle non-string cases)\n",
    "        tokens = tokenize_message(message)\n",
    "\n",
    "        if tokens:  # Skip messages that couldn't be tokenized (empty or non-string)\n",
    "            print(f\"\\nMessage {index + 1}: {message}\")\n",
    "\n",
    "            # Annotate tokens\n",
    "            labeled_tokens = annotate_message(tokens)\n",
    "\n",
    "            # Append labeled tokens\n",
    "            labeled_data.append(labeled_tokens)\n",
    "\n",
    "    # Save the annotated data in CoNLL format\n",
    "    save_to_conll(labeled_data, output_file)\n",
    "    print(f\"\\nAnnotated data saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Provide the path to the dataset and the output file\n",
    "    dataset_path = \"../data/cleaned_dataset.csv\"\n",
    "    output_file = \"../data/labeled_data.txt\"\n",
    "\n",
    "    # Specify the starting row and number of rows to process\n",
    "    start_row = int(input(\"Enter the starting row: \"))\n",
    "    num_rows = int(input(\"Enter the number of rows to label: \"))\n",
    "\n",
    "    main(dataset_path, output_file, start_row, num_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
